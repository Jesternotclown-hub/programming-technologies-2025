# Министерство науки и высшего образования РФ ФГБОУ ВО Заполярный государственный институт имени Н.М.Федоровского

## Технологии программирования. Лабораторная работа №0 Тема: «Установка локальной модели Qwen»

_Работу выполнил:_

_Студент группы ИС-22_

_Шелепов Денис Владимирович_

_Работу проверил:_

_Сидельников Максим Эдуардович_

_Дата выполнения работы: 20.10.2025_

### Цель:

Установить на рабочую машину локальную модель нейросети Qwen и запустить её.

### План

- Настройка окружения;
- Запуск языковой модели;
- Задания.

## Ход работы

Для выполнения лабораторной работы взамен модели Qwen была использована модель Meta-Llama-3.1-8B-Instruct-Q5_K_M, ввиду характеристик имеющейся видеокарты (Nvidea GForce RTX 3050 8Gb). Данная модель успешно выполняла поставленные задачи.

В рамка проведения работы было составлено 2 промпта, регулирующих поведение и стилистику речи модели.

Первый промпт:

> [Роль: Сеньор JavaScript разработчик]
> [Стек: JavaScript, TypeScript, PostgreSQL]
> [Уровень: Эксперт с 10+ годами опыта]
> [Стиль объяснений: Детальный, практико-ориентированный, с акцентом на лучшие практики]
> [Особенность: В каждом ответе добавляет один дополнительный пример из JS/TS для лучшего понимания]
> [Цель: Давать максимально полезные и применимые на практике объяснения]

Данный промпт оказался для модели легким

![JS_Senior](Images/4.png)

Как видно из изображения модель справилась с поставленной характеристикой. В качестве ответа на вопрос "Что такое PARTITION BY?" модель дала ответ на яхыке программирования TS, несмотря на то что PARTITION BY является аргументом оконной функции в SQL.

Второй промпт:

> [Роль: Рик Санчез]
> [Стиль речи: циничный, саркастичный, отрывистый, с использованием научного жаргона и ненормативной лексики (замены: "блин", "черт")]
> [Ключевые характеристики: постоянно употребляет "Мы", начинает ответы с "Бурп...", использует культовые фразы ("Wubba Lubba Dub Dub", "Соберись, тряпка"), презирает сентиментальность, говорит быстро и невнятно, с паузами (...), обрывает предложения]
> [Личность: самый умный человек в мультивселенной, алкоголик, социопат, скрывающий травмы за грубостью]
> Твоя задача: отвечать на все вопросы так, как это сделал бы Рик Санчез.

![alt text](Images/3.png)

![alt text](Images/2.png)

![alt text](Images/1.png)

Как представленно на изображениях, с данной задачей модель от Meta так же справилась, пусть и не точно, повторяя повадки персанажа Рика Санчеза из мультсериала "Рик и Морти"

Для сравнения, пример работы с промптом от нейросети Deep Seek
![alt text](Images/5.png)

## Параметры модели

### Temperature

Temperature контролирует случайность текста, генерируемого LLM во время вывода. Путем настроек и проведений тество было выявлено оптимальное значение. От 0.8 до 1.5. В пределах этих значений сгенерированный текст был логичен и понятен при чтении

### min_p

Выбираются токены которые больше или равны пороговому значению.
Порог = вероятность токена \* min_p

### top_p

Суммируюутся самые вероятные токены до тех пор пока сумма не станет больше или равна p
Выборка идет из токенов, вероятность которых попала в суммирование

### top_k

Выбор k самых вероятных токенов. Идет ограничение по количеству или же словарному запасу ответа модели
